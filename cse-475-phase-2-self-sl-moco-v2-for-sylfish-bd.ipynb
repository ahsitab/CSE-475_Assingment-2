{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **0. Custom Environment Setup (Dependency Fix)**\n",
    "\n",
    "\n",
    "\n",
    "### **Objective**\n",
    "\n",
    "Kaggle's default environment currently includes versions of `numpy` (2.x) and `opencv` (4.10+) that are mutually incompatible, causing \"imdecode\" errors during validation.\n",
    "\n",
    "\n",
    "\n",
    "### **The Solution: Private Environment**\n",
    "\n",
    "Instead of fighting the pre-installed system libraries, we create a **private Python environment** inside the working directory:\n",
    "\n",
    "1.  **Isolation:** We create a folder `/kaggle/working/my_env` to host our own library versions.\n",
    "\n",
    "2.  **Priority:** We insert this folder at the top of `sys.path`, forcing Python to load our libraries *before* the system defaults.\n",
    "\n",
    "3.  **Stability:** We force-install stable versions (`numpy<2.0`, `opencv==4.8.0`) that are known to work flawlessly with YOLOv12.\n",
    "\n",
    "\n",
    "\n",
    "**Why this works:** It bypasses the \"Dependency Hell\" of the default Docker image without requiring a kernel restart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "\n",
    "\n",
    "# --- 1. SETUP PRIVATE ENVIRONMENT ---\n",
    "\n",
    "# We create a separate folder to install working versions of OpenCV and Numpy\n",
    "\n",
    "TARGET_DIR = \"/kaggle/working/my_env\"\n",
    "\n",
    "if not os.path.exists(TARGET_DIR):\n",
    "    os.makedirs(TARGET_DIR)\n",
    "\n",
    "\n",
    "\n",
    "# Add to Python Path immediately so we use these versions\n",
    "\n",
    "if TARGET_DIR not in sys.path:\n",
    "    sys.path.insert(0, TARGET_DIR)\n",
    "\n",
    "\n",
    "\n",
    "print(\"ðŸš€ Installing compatible environment (Numpy 1.x + OpenCV 4.8)...\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# Force install into our private folder\n",
    "\n",
    "# We explicitly downgrade numpy and opencv to versions that play nice together\n",
    "\n",
    "subprocess.check_call([\n",
    "    sys.executable, \"-m\", \"pip\", \"install\",\n",
    "    \"--target\", TARGET_DIR,\n",
    "    \"numpy<2.0\",                      # Fix 1: Old Numpy\n",
    "    \"opencv-python-headless==4.8.0.76\", # Fix 2: Stable OpenCV\n",
    "    \"torch==2.0.1\",                   # Explicit Torch version for compatibility with ultralytics\n",
    "    \"torchvision==0.15.2\",            # Explicit torchvision version for compatibility with ultralytics\n",
    "    \"ultralytics\",                    # Install YOLO\n",
    "    \"pandas\",\n",
    "    \"matplotlib\",\n",
    "    \"--upgrade\",\n",
    "    \"--no-user\",\n",
    "    \"--quiet\"\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "print(\"âœ… Environment Ready.\")\n",
    "\n",
    "\n",
    "\n",
    "# --- 2. VERIFY VERSIONS ---\n",
    "\n",
    "# This proves the fix worked\n",
    "\n",
    "import numpy\n",
    "\n",
    "import cv2\n",
    "\n",
    "print(f\"ðŸ”¹ Numpy Version: {numpy.__version__} (Should be 1.26.x)\")\n",
    "\n",
    "print(f\"ðŸ”¹ OpenCV Version: {cv2.__version__} (Should be 4.8.0)\")\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import json\n",
    "import yaml\n",
    "import random\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ultralytics import YOLO\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "\n",
    "# --- 1. RECONNECT TO PRIVATE ENVIRONMENT ---\n",
    "\n",
    "TARGET_DIR = \"/kaggle/working/my_env\"\n",
    "\n",
    "if TARGET_DIR not in sys.path:\n",
    "    sys.path.insert(0, TARGET_DIR)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"âœ… Connected to private env.\")\n",
    "\n",
    "\n",
    "\n",
    "# --- 2. DEFINE PATHS ---\n",
    "\n",
    "input_dir = Path('/kaggle/input/syfish-bd/Sylfish_bd')\n",
    "annotations_dir = input_dir / 'annotations'\n",
    "images_dir = input_dir / 'images'\n",
    "BASE_DIR = '/kaggle/working/ssl_experiment'\n",
    "LABELED_DIR = f'{BASE_DIR}/labeled_data'\n",
    "\n",
    "\n",
    "\n",
    "# Classes\n",
    "\n",
    "classes = ['boal', 'ilish', 'kalibaush', 'katla', 'koi', 'mrigel', 'pabda', 'rui', 'telapia']\n",
    "class_to_id = {cls: i for i, cls in enumerate(classes)}\n",
    "\n",
    "\n",
    "\n",
    "# Clean up old run\n",
    "\n",
    "if os.path.exists(BASE_DIR):\n",
    "    shutil.rmtree(BASE_DIR)\n",
    "\n",
    "\n",
    "\n",
    "# Create Directories - FIXED: Create all necessary directories\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    os.makedirs(f\"{LABELED_DIR}/{split}/images\", exist_ok=True)\n",
    "    os.makedirs(f\"{LABELED_DIR}/{split}/labels\", exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "# --- 3. COLLECT ALL ANNOTATION FILES ---\n",
    "\n",
    "all_files = []\n",
    "\n",
    "for cls in classes:\n",
    "    ann_dir = annotations_dir / cls\n",
    "    if ann_dir.exists():\n",
    "        files = list(ann_dir.glob('*.json'))\n",
    "        all_files.extend([(f, cls) for f in files])\n",
    "\n",
    "\n",
    "\n",
    "print(f\"ðŸ“Š Total annotation files: {len(all_files)}\")\n",
    "\n",
    "\n",
    "\n",
    "# --- 4. SPLIT DATA (20% labeled train, 20% val, 10% test) ---\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(all_files)\n",
    "\n",
    "\n",
    "\n",
    "# First split: 20% for labeled training, 80% for temp\n",
    "\n",
    "train_files, temp_files = train_test_split(all_files, test_size=0.8, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Second split: From temp, take 20% for val, 10% for test\n",
    "\n",
    "val_files, test_files = train_test_split(temp_files, test_size=0.125, random_state=42)  # 0.125 = 10% / 80%\n",
    "\n",
    "\n",
    "\n",
    "print(f\"ðŸ“Š Train: {len(train_files)} (20%), Val: {len(val_files)} (20%), Test: {len(test_files)} (10%)\")\n",
    "\n",
    "\n",
    "\n",
    "# --- 5. CONVERT ANNOTATIONS TO YOLO FORMAT ---\n",
    "\n",
    "def convert_annotation(json_path, cls, split):\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    image_path = images_dir / cls / data['imagePath']\n",
    "    if not image_path.exists():\n",
    "        print(f\"âš ï¸ Image not found: {image_path}\")\n",
    "        return False\n",
    "    \n",
    "    # Get image size\n",
    "    img = Image.open(image_path)\n",
    "    img_width, img_height = img.size\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    output_images_dir = Path(LABELED_DIR) / split / 'images'\n",
    "    output_images_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Copy image to output - FIXED: Use correct output path\n",
    "    output_image_filename = f'{cls}_{data[\"imagePath\"]}'\n",
    "    output_image_path = output_images_dir / output_image_filename\n",
    "    shutil.copy(image_path, output_image_path)\n",
    "    \n",
    "    # Create label directory if it doesn't exist\n",
    "    output_labels_dir = Path(LABELED_DIR) / split / 'labels'\n",
    "    output_labels_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Create label file\n",
    "    label_filename = f'{cls}_{Path(data[\"imagePath\"]).stem}.txt'\n",
    "    label_file = output_labels_dir / label_filename\n",
    "    \n",
    "    with open(label_file, 'w') as f:\n",
    "        for shape in data['shapes']:\n",
    "            if shape['shape_type'] == 'rectangle':\n",
    "                points = shape['points']\n",
    "                x_min = min(points[0][0], points[1][0])\n",
    "                y_min = min(points[0][1], points[1][1])\n",
    "                x_max = max(points[0][0], points[1][0])\n",
    "                y_max = max(points[0][1], points[1][1])\n",
    "                \n",
    "                width = x_max - x_min\n",
    "                height = y_max - y_min\n",
    "                \n",
    "                x_center = x_min + width / 2\n",
    "                y_center = y_min + height / 2\n",
    "                \n",
